/cluster/home/ZhongYeah/anaconda3/envs/dex1/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/cluster/home/ZhongYeah/anaconda3/envs/dex1/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/cluster/home/ZhongYeah/anaconda3/envs/dex1/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.
  warnings.warn(
train_10_one.py:234: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model.load_state_dict(torch.load(BEST_MODEL_DIR))
Epoch [1/50] | Train Loss: 0.305974 | Val Loss: 0.167757
Best model saved with val loss: 0.167757
Epoch [2/50] | Train Loss: 0.159514 | Val Loss: 0.104101
Best model saved with val loss: 0.104101
Epoch [3/50] | Train Loss: 0.138350 | Val Loss: 0.077808
Best model saved with val loss: 0.077808
Epoch [4/50] | Train Loss: 0.121303 | Val Loss: 0.088047
Epoch [5/50] | Train Loss: 0.105538 | Val Loss: 0.071348
Best model saved with val loss: 0.071348
Epoch [6/50] | Train Loss: 0.103683 | Val Loss: 0.063890
Best model saved with val loss: 0.063890
Epoch [7/50] | Train Loss: 0.096071 | Val Loss: 0.058311
Best model saved with val loss: 0.058311
Epoch [8/50] | Train Loss: 0.086539 | Val Loss: 0.062485
Epoch [9/50] | Train Loss: 0.086508 | Val Loss: 0.057155
Best model saved with val loss: 0.057155
Epoch [10/50] | Train Loss: 0.073571 | Val Loss: 0.055037
Best model saved with val loss: 0.055037
Epoch [11/50] | Train Loss: 0.071837 | Val Loss: 0.049158
Best model saved with val loss: 0.049158
Epoch [12/50] | Train Loss: 0.068308 | Val Loss: 0.055462
Epoch [13/50] | Train Loss: 0.069895 | Val Loss: 0.050433
Epoch [14/50] | Train Loss: 0.064209 | Val Loss: 0.052024
Epoch [15/50] | Train Loss: 0.061112 | Val Loss: 0.049581
Epoch [16/50] | Train Loss: 0.053872 | Val Loss: 0.052009
Epoch [17/50] | Train Loss: 0.060868 | Val Loss: 0.052557
Epoch [18/50] | Train Loss: 0.044464 | Val Loss: 0.040655
Best model saved with val loss: 0.040655
Epoch [19/50] | Train Loss: 0.041714 | Val Loss: 0.048518
Epoch [20/50] | Train Loss: 0.039316 | Val Loss: 0.041891
Epoch [21/50] | Train Loss: 0.036754 | Val Loss: 0.041715
Epoch [22/50] | Train Loss: 0.035156 | Val Loss: 0.054246
Epoch [23/50] | Train Loss: 0.042612 | Val Loss: 0.049177
Epoch [24/50] | Train Loss: 0.036327 | Val Loss: 0.044937
Epoch [25/50] | Train Loss: 0.028668 | Val Loss: 0.039132
Best model saved with val loss: 0.039132
Epoch [26/50] | Train Loss: 0.027813 | Val Loss: 0.038043
Best model saved with val loss: 0.038043
Epoch [27/50] | Train Loss: 0.024261 | Val Loss: 0.040875
Epoch [28/50] | Train Loss: 0.024721 | Val Loss: 0.039665
Epoch [29/50] | Train Loss: 0.024534 | Val Loss: 0.041487
Epoch [30/50] | Train Loss: 0.026193 | Val Loss: 0.044429
Epoch [31/50] | Train Loss: 0.024407 | Val Loss: 0.042163
Epoch [32/50] | Train Loss: 0.022329 | Val Loss: 0.039891
Epoch [33/50] | Train Loss: 0.019733 | Val Loss: 0.041994
Epoch [34/50] | Train Loss: 0.017277 | Val Loss: 0.039110
Epoch [35/50] | Train Loss: 0.017280 | Val Loss: 0.038469
Epoch [36/50] | Train Loss: 0.016783 | Val Loss: 0.039256
Epoch [37/50] | Train Loss: 0.020176 | Val Loss: 0.037784
Best model saved with val loss: 0.037784
Epoch [38/50] | Train Loss: 0.018506 | Val Loss: 0.037791
Epoch [39/50] | Train Loss: 0.015823 | Val Loss: 0.039318
Epoch [40/50] | Train Loss: 0.014712 | Val Loss: 0.042658
Epoch [41/50] | Train Loss: 0.014960 | Val Loss: 0.042927
Epoch [42/50] | Train Loss: 0.016484 | Val Loss: 0.036861
Best model saved with val loss: 0.036861
Epoch [43/50] | Train Loss: 0.014477 | Val Loss: 0.040007
Epoch [44/50] | Train Loss: 0.013942 | Val Loss: 0.037889
Epoch [45/50] | Train Loss: 0.013859 | Val Loss: 0.038903
Epoch [46/50] | Train Loss: 0.012546 | Val Loss: 0.038056
Epoch [47/50] | Train Loss: 0.012502 | Val Loss: 0.042938
Epoch [48/50] | Train Loss: 0.015552 | Val Loss: 0.039330
Epoch [49/50] | Train Loss: 0.012621 | Val Loss: 0.037509
Epoch [50/50] | Train Loss: 0.011289 | Val Loss: 0.037898
Training completed!
Final Validation Loss: 0.036861